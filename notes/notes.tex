\input article
\input macros

\def\baseDir{/afs/cern.ch/work/j/jkaspar/analyses/elastic/6500GeV/beta2500/2rp/}

\def\section#1{%
	\advance\nsec1
	\nsubsec=0 
	\nssubsec=0%
	\penalty-\clubpenalty
	\vskip2\baselineskip
	{%
		\baselineskip15pt
		\vbox{%
			\noindent\SetFontSizesXII\bf\the\nsec. #1%
		}%
	}%
	\penalty\clubpenalty
	\vskip0\baselineskip
	\parindent=0pt
	\everypar={\parindent=\ParIndent \everypar={}}%
}

\def\subsection#1{%
	\advance\nsubsec1
	\nssubsec=0%
	\penalty-\clubpenalty
	\vskip2\baselineskip
	{%
		\vbox{%
			\noindent\bf\the\nsec.\the\nsubsec. #1%
		}%
	}%
	\penalty\clubpenalty
	\vskip0\baselineskip
	\parindent=0pt
	\everypar={\parindent=\ParIndent \everypar={}}%
}

\def\linkColor{\cBlue}

%----------------------------------------------------------------------------------------------------

\centerline{\SetFontSizesXX Elastic analysis, $\sqrt s = 13\un{TeV}$, $\be^* = 2500\un{m}$}
\vskip2mm
\centerline{\SetFontSizesXX analysis with 2 RPs }
\vskip2mm
\centerline{version: {\it \number\day. \number\month. \number\year}}

%----------------------------------------------------------------------------------------------------
\section{Analysis approach}

\> RPs used (track required): 220-fr unit in both arms

%----------------------------------------------------------------------------------------------------
\section{Datasets}

\> fills: 5313, 5314, 5317, 5321

%----------------------------------------------------------------------------------------------------
\section{Beam conditions}

\> naming
\>> ``unresolved'' activity: event where RP has sufficient number of planes on, but no track is reconstructed

\> plots of rates vs.~time
\>> \plot{common/rates_vs_time.pdf}: basic rates
\>> \plot{common/multitrack_rates_vs_time.pdf}: details for the unresolved category


%----------------------------------------------------------------------------------------------------
\section{Ntuples}

\> currently used: /eos/totem/data/offline/2016/2500m/version1/

%----------------------------------------------------------------------------------------------------
\section{Hit distributions}

\> \plot{hit_distributions/hit_distributions.pdf}: hit distribution after elastic event selection

%----------------------------------------------------------------------------------------------------
\section{Reconstruction formulae}

\> \plot{reconstruction_formulae/plot_formulae_graphs.pdf} : study of performance of various reconstruction formulae
\>> formulae
\>>> using different RPs as input
\>>> combining the input in various ways
\>> studying the impact of various effects: beam divergence, vertex, pitch, ...

\> \plot{reconstruction_formulae/plot_formulae_correlation.pdf} : study of left-right correlations of angle reconstruction errors
\>> significant in $x$ due to neglecting $x^*$

\> formulae used
\>> horizontal plane
\>>> single arm: $x / L_x$
\>>> double arm: average of single arm
\>> vertical plane
\>>> single arm: $y / L_y$
\>>> double arm: average of single arm

%----------------------------------------------------------------------------------------------------
\section{Cuts/elastic tagging}

\> event selection
\>> track in 220-fr units of a diagonal
\>> elastic tagging, see below
\>> RP trigger flag: non zero (ev.trigger\_bits \& 7)

\> elastic tagging: general cut structure $| a q_a + b q_b + c| < n_\si  \si$
\>> cut 1: $q_a = \th_x^{*R}$, $q_b = \th_x^{*L}$; \plot{cuts/cut_1.pdf}
\>> cut 2: $q_a = \th_y^{*R}$, $q_b = \th_y^{*L}$; \plot{cuts/cut_2.pdf}

\> all cuts applied at $n_\si = 4$ level

\> \plot{cut_parameters_vs_time.pdf} : cut parameters as function of time
\>> mean: maximum offset from zero about $0.15\un{\si}$
\>>> negligible impact as cuts applied at $n_\si$
\>> sigma: taking the maximum for cuts
\>>> cut 1: $\si = 14\un{\mu rad}$
\>>> cut 2: $\si = 0.4\un{\mu rad}$


%----------------------------------------------------------------------------------------------------
\section{Efficiency and purity of cuts, background}

\subsection{Background studies}

\> background: non-elastic events passing the tagging cuts

\> ``anti-diagonal`` data
\>> from configurations: 45 top -- 56 top, 45 bot -- 56 bot
\>> sign of $y$ swapped in sector 45 to process the data with the standard chain
\>> cannot contain any signal
\>> background expected similar as in diagonals

\> methods
\>> method 1: plot distributions of cut discriminators under various cut combinations, see\\ \plot{background,cut_efficiency/cut_distributions.pdf}
\>>> central part (signal): unaffected by cuts
\>>> tails (background): drops with increasing number of cuts
\>>> however: unknown interpolation of background from tails to the signal region
\>> method 2: plot distributions of cut discriminators also for anti-diagonal configurations, see\\ \plot{background,cut_efficiency/cut_dist_antidgn_cmp.pdf}
\>>> relatively good agreement in tails -- confirmation that the background is indeed similar in diagonals and anti-diagonals
\>>> anti-diagonals provide shape of interpolation to the signal region -- flat

\> results
\>> \plot{background,cut_efficiency/cut_dist_antidgn_cmp.pdf}: distributions of cut discriminators, after all available cuts, comparison between diagonal and anti-diagonal configurations
\>>> by comparing the signal (diagonals) and background (anti-diagonals) peak: rough estimate of $B/S = \O{0.1\un{\%}}$

\>> \plot{background,cut_efficiency/t_dist_antidgn_cmp.pdf}: $t$-distributions, after all available cuts, comparison between diagonal (mostly signal) and anti-diagonal (background) configurations
\>>> background / signal at low $|t|$: $\approx 0.1\un{\%}$
\>>> background / signal at $|t| \ls 0.2\un{GeV^2}$: negligible (per-mille level)
\>>> background / signal at dip: up to $10\un{\%}$


\> additional material
\>> \plot{background,cut_efficiency/t_distributions_cuts.pdf}: $t$-distributions under various cut combinations

\subsection{Study of signal loss due to cuts}

\> method
\>> plot $t$ distributions at different cut levels ($n_\si$)

\> \plot{background,cut_efficiency/t_distributions_n_si_cmp_fill.pdf}: $t$ distribution at different cut levels, for all fills
\>> qualitatively similar results from all fills

\> \plot{background,cut_efficiency/t_distributions_n_si_cmp_binning.pdf}: $t$ distribution at different cut levels, for all binnings
\>> with fine binnings, bands visible
\>>> most likely because of the difference in bin contents is a small integer: 1, 2, 3, ...
\>>> for $|t| \gs 0.4\un{GeV^2}$, the relative differences are larger when smaller bins -- large interplay with statistics

\> results
\>> $|t| \ls 0.2\un{GeV^2}$
\>>> difference between $n_\si = 4$ (standard) and $5$ is below $0.2\un{\%}$ and almost flat
\>> $|t| \gs 0.4\un{GeV^2}$
\>>> difference between $n_\si = 4$ (standard) and $5$ is few percent
\>>> differences covered by statistical uncertainties

%----------------------------------------------------------------------------------------------------
\section{Efficiency studies}

\vskip3mm
Each event is weighted with the following correction factor
\eqref{
	{1\over 1 - I_{\rm trig}}\ 
	{1\over 1 - I_{\rm DAQ}}
	{1\over 1 - I_{\rm PU}}\ 
	{1\over 1 - I_{1RP} - I_{\rm 2RP}}\ ,
}{eff corr}
where symbols $I$ stand for various inefficiencies discussed below.

\subsection{Trigger efficiency}

\> method:
\>> take zero-bias (BX) data
\>>> using bit 9 (e.g.~https://twiki.cern.ch/twiki/bin/view/TOTEM/90m)
\>>> i.e.~ev.trigger\_bits \& 512
\>> select elastic events (standard tagging) $\rightarrow$ number of events $N({\rm BX,elastic})$
\>> out of the selected events, check how many have trigger flag on $\rightarrow$ number of events $N({\rm BX,elastic,trigger})$
\>>> trigger flag = ev.trigger\_bits \& 7 (i.e.~any of the bits 0, 1 and 2)
\>> then trigger efficiency is obtained as follows:

$$1 - I_{\rm trig} = {N({\rm BX,elastic,trigger}) \over N({\rm BX,elastic})}$$

\> results:
\>> fill 5317, diagonal 45 bot -- 56 top: $N({\rm BX,elastic}) = N({\rm BX,elastic,trigger}) = 7911$
\>> fill 5317, diagonal 45 top -- 56 bot: $N({\rm BX,elastic}) = N({\rm BX,elastic,trigger}) = 7190$

\> this correction is not applied since it does not modify $t$-distribution shape


\subsection{DAQ efficiency}

\> method: per time slice calculate from the trigger block of raw data:
$$\hbox{DAQ efficiency} = {N(\hbox{recorded events})\over N(\hbox{triggered events})} \equiv 1 - I_{\rm DAQ}$$

\> \plot{efficiencies/daq_efficiency.pdf}: DAQ efficiency as function of time

\> this correction is not applied since it does not modify $t$-distribution shape



\subsection{Pile-up}

\> method
\>> take BX sample, split it into time slices
\>> per RP, evaluate frequency of ``destructive`` signal that would break reconstruction if piled up with an elastic event

$$I^{i}_{\rm PU} = {N(\hbox{destructive signal in RP $i$})\over N(\hbox{anything})}$$

\>> typical conditions of ``destructivity``
\>>> ``pl\_suff'': sufficient number of planes is on
\>>> ``pat\_suff'': at least one U or V pattern is recognised 
\>> use OR between left and right arm -- it is sufficient to loose any arm to loose the elastic event

$$I_{\rm PU} = {N(\hbox{destructive signal in any 220-fr RP})\over N(\hbox{anything})}$$


\> \plot{efficiencies/pileup_details.pdf}: contributions from each arm and their combination, per diagonal

\> \plot{efficiencies/pileup.pdf}: final inefficiency as a function of time

\> this correction is not applied since it does not modify $t$-distribution shape


\subsection{Uncorrelated single RP inefficiencies (3-out-of-4)}

\> method: derive from results of the 4-RP analysis
\>> transfer validation: \plot{efficiencies/eff3outof4_fits_summary_cmp_4rp_anal.pdf}
\>> take the results for 220-fr pots only

$$I_{\rm 1RP}(\th_y^*) = \sum\limits_{i \in\hbox{\SmallerFonts 220-fr}} I_{\rm 1RP}^i$$

\> typical form of $I_{\rm 1RP}(\th_y^*)$: linear in $\th^*_y$
\>> value at $\th_y^* = 0$: typically about $6.9\un{\%}$
\>> slope: typically about $150\un{rad^{-1}}$

\> uncertainties of $I_{\rm 1RP}(\th_y^*)$
\>> value at $\th_y^* = 0$: $0.3\un{\%}$
\>> slope: $15\un{rad^{-1}}$

\> this correction is applied since it modifies the $t$-distribution shape


\subsection{Correlated RP inefficiencies}

\> typical case: shower initiated upstream (210-far) propagates downstream (220-far)
\>> this is not included in the uncorrelated single-RP inefficiency above

\> method: external study (Geant4, data driven check at $\sqrt s = 8\un{TeV}$)
\>> inefficiency per arm: $(1.5 \pm 0.7)\un{\%}$ (e.g.~from 1km or non-exponential paper)
\>> total inefficiency (two arms):

$$I_{2RP} = (3 \pm 1)\un{\%}$$

\> this correction is applied since it modifies the $t$-distribution shape



%----------------------------------------------------------------------------------------------------
\section{Alignment}

\subsection{Determination}

\> method: standard procedure
\>> beam-based alignment: before data-taking
\>> track-based alignment: relative alignment between RP sensors
\>> alignment with elastics: absolute alignment wrt.~LHC beam

\> uncertainty of track-based alignment
\>> horizontal shift: $5\un{\mu m}$
\>> vertical shift: $5\un{\mu m}$
\>> rotation about $z$: $1\un{mrad}$

\> uncertainty of elastic alignment
\>> horizontal shift: $25\un{\mu m}$
\>> vertical shift: $100\un{\mu m}$
\>> rotation about $z$: $2\un{mrad}$

\> induced uncertainties
\>> shift in 2-arm $\th_x^*$: $0.35\un{\mu rad}$
\>> shift in 2-arm $\th_y^*$: $0.24\un{\mu rad}$
\>> rotation about z: $\th_x^* \rightarrow \th_x^* + C \th_y^*$, $\si(C) = 0.012$

\subsection{Validation}

\> \plot{alignment/angular_diff_vs_time.pdf}: differences (left-right, 210m-220m) in reconstructed scattering angles

\> \plot{alignment/mean_th_x_vs_th_y.pdf}: mean of $\th_x^*$ as a function of $\th_y^*$ -- test for residual mis-rotations

\> \plot{alignment/mean_th_x_vs_time.pdf}:  mean of $\th_x^*$ as a function of time -- test for stability of $x$ alignment

\> observations (2 arm)
\>> shift in $\th_x^*$: $\De^{R-L} \th_x^*$ up to $1\un{\mu rad}$, the above estimate gives RMS of $0.7\un{\mu rad}$ thus quite compatible; maximum of $\De^{R-L} \th_x^*$ only occurs seldom; for safety take $0.5\un{\mu rad}$ for the two-arm uncertainty
\>> shift in $\th_y^*$: compatible with above estimate $0.24\un{\mu rad}$
\>> rotation about z: $\si(C) \approx 0.005$ significantly better than the above estimate, use this value
\>> 2D Gaussian fit of $\th^*_y$ vs $\th^*_x$ distributions combined from the two diagonals (program alignment\_final) gives centre positions
\>>> $|\th^*_x| < 0.03\un{\mu rad}$
\>>> $|\th^*_y| < 0.06\un{\mu rad}$


%----------------------------------------------------------------------------------------------------
\section{Optics}

\subsection{Validation}

\> \plot{optics/optics_test_summary.pdf}: left-right differences in reconstructed scattering angles plotted as a function of the scattering angle
\>> shifts (fit extrapolated to 0): due to misalignments
\>> tilts (slope): due to optics
\>>> within $0.1\un{\%}$ -- for the moment, use this as uncertainty estimate independently for scaling $\th_x^*$ and $\th_y^*$



%----------------------------------------------------------------------------------------------------
\section{Resolutions}

\> method
\>> horizontal plane
\>>> single arm $\th_x^*$ reconstruction biased by neglecting $x^*$
\>>> this bias in left-right antisymmetric, see \plot{reconstruction_formulae/plot_formulae_correlation.pdf}
\>>> therefore $\De^{R-L} \th_x^*$ is dominated by the vertex term
\>>> and the 2-arm reconstruction (L-R average) is almost free of the bias
\>>> this can not be extracted directly from data, but can be studied with a MC tuned to the 4-RP analysis
\>> vertical plane
\>>> left-right difference of $\th_y^*$ directly probes the vertical beam divergence (the detector component is negligible)

\> \plot{resolutions/resolutions_vs_time.pdf} : time-dependence of observed $\si(\De^{R-L} \th_{x, y}^*)$
\>> solid line: compilation of per-run linear fits (excluding points with too large errors)

\> $d_{x, y}$ (R-L difference of $\th_{x, y}^*$): used for acceptance correction
\>> time dependent
\>> central values and uncertainties from \plot{resolutions/resolutions_vs_time.pdf}
\>> uncertainties:
\>>> x: $0.3\un{\mu rad}$
\>>> y: $0.007\un{\mu rad}$

\> $m_{x, y}$ (R-L mean of $\th_{x, y}^*$): used for resolution unfolding
\>> for the moment: time independent, single value for all fills
\>> uncertainty covers the full time and fill dependence
\>> x: from 4-RP analysis plus MC -- considered two extreme cases
\>>> case 1: $\si(x^*) = 480\un{\mu m}$, $\si^{\rm bd}(\th^*_x) = 0.27\un{\mu rad}$, $\si^{\rm sen}(x) = 11\un{\mu m}$
\>>> case 2: $\si(x^*) = 680\un{\mu m}$, $\si^{\rm bd}(\th^*_x) = 0.39\un{\mu rad}$, $\si^{\rm sen}(x) = 12\un{\mu m}$
\>>> \plot{reconstruction_formulae/plot_formulae_graphs_desc_th_x.pdf}: MC shows that the impact of vertex in 2-arm reconstruction can be neglected wrt.~beam divergence and sensor resolution
\>>> case 1: MC gives $\si(m_x) = 0.25\un{\mu rad}$
\>>> case 2: MC gives $\si(m_x) = 0.33\un{\mu rad}$
\>>> mean and difference from the two cases: $\si(m_x) = (0.29 \pm 0.04)\un{\mu rad}$
\>> y: from \plot{resolutions/resolutions_vs_time.pdf}, $\si(m_y) = (0.185 \pm 0.010)\un{\mu rad}$


%----------------------------------------------------------------------------------------------------
\section{Acceptance correction}

\subsection{Theory}

\vskip3mm

The smearing (beam, detector, ...) can be formally described as change of the true scattering angle, $\th_x$, to the reconstructed angle, $\th'_x$, (for brevity the stars are suppressed):
\eqref{
\th'_x = \th_x + \De \th_x
}{de th x}
The smearing may be different the left (L) and right (R) arm and can be decomposed as
\eqref{
\De\th_x^{\rm R} = m_x + {\d_x\over 2}\ ,\qquad \De\th_x^{\rm L} = m_x - {\d_x\over 2}\ ,
}{m d to th L R}
where $m_x$ modifies the L-R average while $d_x$ modifies the L-R difference:
\eqref{
m_x = {\De\th_x^{\rm R} + \De\th_x^{\rm L}\over 2}\ ,\qquad d_x = \De\th_x^{\rm R} - \De\th_x^{\rm L}\ .
}{th L R to m d}

The smearing and acceptance effects can then be described as transformation from true, $h_{\rm true}$, to reconstructed, $h_{\rm reco}$, probability distribution functions (PDFs):
\eqref{
\eqnarray{
	h_{\rm reco}(\th'_x, \th'_y) & = & \int \d\th_x \int \d\th_y\ h_{\rm true}(\th_x, \th_y) \cr
								 &  & \cdot \int \d m_x\ G_{m_x}(m_x) \int \d m_y\ G_{m_y}(m_y) \cr
								 &  & \cdot \int \d d_x\ G_{d_x}(d_x) \int \d d_y\ G_{d_y}(d_y) \cr
								 &  & \cdot \de\left( \th'_x - (\th_x + m_x) \right) \cr
								 &  & \cdot \de\left( \th'_y - (\th_y + m_y) \right) \cr
								 &  & \cdot \Th(\hbox{acc.~cond.}) \ ,\cr
}
}{sm acc model}
where the $G$ functions give distributions of the smearing parameters, thus the model assumes that the $m_{x,y}$ and $d_{x,y}$ parameters are independent (uncorrelated). The $\Th$ function expresses the acceptance condition. As the condition can be written in terms of $\th'_{x,y}$ and $d_{x,y}$, i.e.~the cuts are done in the smeared coordinates, \Eq{sm acc model} can be factorised as
\eqref{
	h_{\rm reco}(\th'_x, \th'_y) = h_{\rm smear}(\th'_x, \th'_y)\ F_{\rm acc}(\th'_x, \th'_y)\ .
}{sm acc model fac}
The first factor
\eqref{
\eqnarray{
	h_{\rm smear}(\th'_x, \th'_y) & = & \int \d\th_x \int \d\th_y\ h_{\rm true}(\th_x, \th_y) \cr
								 &  & \cdot \int \d m_x\ G_{m_x}(m_x) \int \d m_y\ G_{m_y}(m_y) \cr
								 &  & \cdot \de\left( \th'_x - (\th_x + m_x) \right) \cr
								 &  & \cdot \de\left( \th'_y - (\th_y + m_y) \right) \cr
}
}{sm model}
gives the PDF corresponding to the case where only smearing was applied. The effect of acceptance cuts is all contained in the second term:
\eqref{
\eqnarray{
	F_{\rm acc}(\th'_x, \th'_y) & = & \int \d d_x\ G_{d_x}(d_x) \int \d d_y\ G_{d_y}(d_y) \cr
								 &  & \cdot \Th(\hbox{acc.~cond.}) \ .\cr
}
}{acc model}

In the data reconstruction, one builds histogram(s) using weight $1 / F_{\rm acc}$ which according to \Eq{sm acc model fac} estimates $h_{\rm smear}$ wherever there is non-zero acceptance. A particularly interesting histogram is in $t$, or in equivalently in $\th$ which can be modelled as
\eqref{H_{\rm smear}(\th) = \int\limits_{\Om(\th)} \ \d\ph\ h_{\rm smear}(\th \cos\ph, \th\sin\ph)\ ,}{sm model th}
where $\Om(\th)$ is a set of $\ph$ values with non-zero acceptance. In order to recover the part with zero acceptance, one can introduce a correction
\eqref{H_{\rm smear,corr}(\th) = {1\over A_{\ph}(\th)} H_{\rm smear}(\th)\ ,}{sm model th corr}
\eqref{A_{\ph}(\th) = {1\over 2\pi} \int\limits_{\Om(\th)} \ \d\ph\ .}{A phi}
This correction assumes azimuthal ($\ph$) symmetry of $h_{\rm smear}$ which is typically slightly broken due to different smearing in $\th_x$ and $\th_y$. The error induced is typically absorbed into the ``unfolding correction'' which is applied in the final step of the analysis.

\subsection{Fiducial cuts}

\> there two types of fiducial cuts
\>> separately in left and right arm
\>>> cuts corresponding to the actual limits (sensors, LHC)
\>>> they correspond to the condition $\Th$ in \Eq{acc model}
\>> cut in global (after averaging) $\th_{x, y}$
\>>> in order to avoid regions where $F_{\rm acc}$ is too small (and thus the corresponding weight too large)
\>>> they enter via the set $\Om$ in \Eq{sm model th}

\> all cuts have two bounds (illustrated in \plot{acceptance_correction/acc_phi_lab.pdf})
\>> at low $|\th_y^*|$: due to sensor edge
\>> at higher $|\th_y^*|$): due to LHC apertures

\> all cuts are defined empirically by selecting a region within which one expects full acceptance ($\Th \equiv 1$ in \Eq{acc model}), shown in \plot{acceptance_correction/acc_cmp_fill_details.pdf}
\>> there is evident effect of the upstream 210-fr RPs which are tilted, causing inefficiency -- this region is cut out

\> \plot{acceptance_correction/fiducial_cut_cmp.pdf}: comparison of fiducial cuts


\subsection{Smearing correction}

\> ``smearing correction'' denotes the factor $1/F_{\rm acc}$
\>> it is calculated according to \Eq{acc model}, assuming Gaussian distributions of $d_{x,y}$, using numerical integration (GSL library)
\>> it is applied as described below \Eq{acc model}


\subsection{$\ph$ correction}

\> ``$\ph$ correction'' refers to $1 / A_{\ph}$
\>> it is calculated according to \Eq{A phi}
\>> it is applied according to \Eq{sm model th corr}


\> \plot{acceptance_correction/acc_cmp_fill.pdf} : verification of the assumed $\ph$ symmetry


\subsection{Program implementation, validation}

\> there are two implementations of \Eq{acc model}
\>> ``old''
\>>> assumes no dependence of acceptance condition of $d_x$, thus integrates over $d_y$ only
\>>> assumes Gaussian distribution of $d_y$
\>> ``new'': no assumptions needed, implemented as numerical integration using routines from GSL
\>>> for performance optimisation, this implementation {\it may} assume gaussianity of $d_y$

\> \plot{acceptance_correction/validation/validation_vs_old.pdf} : comparison of old and new implementations -- perfect agreement

\> \plot{acceptance_correction/validation/validation_gaussian_approx.pdf} : for the new implementation, comparison of results with and without the gaussian optimisation -- perfect agreement

\> below a study with MC is presented; two versions of simulation have been considered:
\>> ``corr'': including the correlation between $m_x$ and $d_x$ ($\rh \approx 0.2$) and correlation between $m_y$ and $d_y$ ($\rh\approx 0.02$)
\>> ``uncorr'': disregarding the correlations
\>> it will be shown that the correlation has no significant effect

\> \plot{acceptance_correction/validation/validation_with_mc_th_y_acc.pdf} : smearing acceptance as a function of $\theta^*_y$ for 3 bands of $\th^*_x$
\>> MC (violet) vs.~calculated correction (black): perfect agreement

\> \plot{acceptance_correction/validation/validation_with_mc_th_y_hist_after_corr.pdf} : for 3 bands of $\th^*_x$, ratio of $\theta^*_y$ distributions -- with smearing only and with smearing+fiducial cuts+smearing acceptance correction
\>> perfectly compatible with 1

\> \plot{acceptance_correction/validation/validation_with_mc_t_dist_cmp.pdf} : comparison of $t$-distributions
\>> black and red histograms perfectly compatible

\> \plot{acceptance_correction/validation/validation_with_mc_t_unsmear_corr.pdf} : comparison of "unsmearing" correction from this MC study (red, blue) and from a dedicated calculation (black)
\>> perfect compatibility



%----------------------------------------------------------------------------------------------------
\section{Unfolding of resolution effects}

\> method
\>> take a fit of data with model including both Coulomb and hadronic contributions
\>> this fits serves as an input (truth) to simulation with and without smearing effects
\>> ratio of these two curves gives unfolding correction
\eqref{U(\th) = {H_{\rm smear,corr}(\th)\over h_{\rm true}(\th)}}{unfold corr}
where the numerator comes from \Eq{sm model th corr} and therefore this correction takes into account the small bias introduced in acceptance correction handling
\>>> in practice the correction $U$ is evaluated as a function of $t$

\> there are two evaluations of \Eq{unfold corr}
\>> numerical integration: fast, accurate
\>> Monte Carlo: very simple implementation, needs long computing time for reasonable accuracy
\>> \plot{unfolding/cmp_mc_num_int.pdf} : comparison of the two methods -- very good agreement

\> \plot{unfolding/num_int_model_cmp.pdf} : dependence on the initial data fit
\>> differences only at high $|t|$, always below $0.1\un{\%}$
\>> the fit "fit2-1" doesn't describe the dip well and should be thus handled with caution

\> results -- as expected
\>>> effects in general small -- very small beam divergence
\>>> effects only present at low $|t|$ (strong non-linearity due to Coulomb) and at dip region

\> \TODO: add comments on uncertainty
\>> model dependence
\>> dependence on $\si(m_x)$
\>> dependence on $\si(m_y)$


%----------------------------------------------------------------------------------------------------
\section{Binning}

\> method: binning ``ob-$\langle n\rangle$-$\langle u\rangle$-$\langle w_m\rangle$`` is built as follows
\>> at low $|t|$ ($|t| \ls 0.4\un{GeV^2}$): bin size about $n\times \si(\hbox{$t$ smearing})$
\>> at mid $|t|$: bin size for a fixed statistical uncertainty $u\un{\%}$
\>> if needed at large $|t|$: constant bin size $w_m$ (in $\rm GeV^2$) to avoid excessively large bins

\> binnings used in analysis
\>> ob-1-20-0.05
\>> ob-2-10-0.05
\>> ob-3-5-0.05

\> \plot{binning/bin_size_vs_t.pdf} : visualisation of binning determinants vs.~several binnings used in
the analysis



%----------------------------------------------------------------------------------------------------
\section{Normalisation}

\> method
\>> normalise $\d\si/\d t$ such that $I + S = 29.7\un{mb}$
\>> $I$ stands for $\d\si/\d t$ fit over $0.01 < |t| < 0.05\un{GeV^2}$, integrated over $0 < |t| < 0.01\un{GeV^2}$
\>> $S$ stands for histogram integral of bins $0.01 < |t| < 0.5\un{GeV^2}$


%----------------------------------------------------------------------------------------------------
\section{$t$-distributions}

\> \plot{t_distributions/t_dist_fill_cmp.pdf}: comparison of $t$-distributions from different fills and diagonals

\> \plot{t_distributions/t_dist_merged.pdf}: full and low-$t$ plots of the merged $t$-distribution

\> \plot{t_distributions/t_dist_rel.pdf}: merged $t$-distribution in a relative frame


%----------------------------------------------------------------------------------------------------
\section{Systematic uncertainties}

\subsection{Effects one by one}

\> preliminary plots
\>> \plot{systematics/cmp_direct_mc_numerical_integration.pdf}


\subsection{Multiple effects}

\> preliminary plots
\>> \plot{systematics/numerical_integration_combined.pdf}
\>> \plot{systematics/numerical_integration_matrix.pdf}


\bye
